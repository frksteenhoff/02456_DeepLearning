{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Method for converting labels to binary values \n",
    "def bin_label(label):\n",
    "    if label ==' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(bin_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = census['income_bracket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop(['income_bracket'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, labels, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
      "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
      "       'capital_loss', 'hours_per_week', 'native_country'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(x_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cont = ['age', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "featco = []\n",
    "for val in feat_cont:\n",
    "    featco.append(tf.feature_column.numeric_column(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cat = ['workclass', 'education', 'marital_status','occupation','relationship', 'gender', 'native_country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "featca = []\n",
    "for val in feat_cat:\n",
    "    featca.append(tf.feature_column.categorical_column_with_vocabulary_list(val,x_data[val].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_VocabularyListCategoricalColumn(key='workclass', vocabulary_list=(' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov', ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay', ' Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n",
      "_VocabularyListCategoricalColumn(key='education', vocabulary_list=(' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th', ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th', ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th', ' Preschool', ' 12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n",
      "_VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=(' Never-married', ' Married-civ-spouse', ' Divorced', ' Married-spouse-absent', ' Separated', ' Married-AF-spouse', ' Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n",
      "_VocabularyListCategoricalColumn(key='occupation', vocabulary_list=(' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners', ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair', ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct', ' Tech-support', ' ?', ' Protective-serv', ' Armed-Forces', ' Priv-house-serv'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n",
      "_VocabularyListCategoricalColumn(key='relationship', vocabulary_list=(' Not-in-family', ' Husband', ' Wife', ' Own-child', ' Unmarried', ' Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n",
      "_VocabularyListCategoricalColumn(key='gender', vocabulary_list=(' Male', ' Female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n",
      "_VocabularyListCategoricalColumn(key='native_country', vocabulary_list=(' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico', ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada', ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland', ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos', ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic', ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan', ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland', ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong', ' Ireland', ' Hungary', ' Holand-Netherlands'), dtype=tf.string, default_value=-1, num_oov_buckets=0)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for it in featca:\n",
    "    print(it)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = featco + featca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=None,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\FRKSTE~1\\AppData\\Local\\Temp\\tmppfx84drb\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\FRKSTE~1\\\\AppData\\\\Local\\\\Temp\\\\tmppfx84drb', '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_tf_random_seed': 1, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "lin_model = tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\FRKSTE~1\\AppData\\Local\\Temp\\tmppfx84drb\\model.ckpt.\n",
      "INFO:tensorflow:loss = 69.3147, step = 1\n",
      "INFO:tensorflow:global_step/sec: 209.525\n",
      "INFO:tensorflow:loss = 763.57, step = 101 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.713\n",
      "INFO:tensorflow:loss = 183.881, step = 201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.847\n",
      "INFO:tensorflow:loss = 191.058, step = 301 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.324\n",
      "INFO:tensorflow:loss = 136.186, step = 401 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.849\n",
      "INFO:tensorflow:loss = 241.906, step = 501 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.668\n",
      "INFO:tensorflow:loss = 56.3952, step = 601 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.445\n",
      "INFO:tensorflow:loss = 130.582, step = 701 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.337\n",
      "INFO:tensorflow:loss = 61.3952, step = 801 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 160.88, step = 901 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.336\n",
      "INFO:tensorflow:loss = 42.3075, step = 1001 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.047\n",
      "INFO:tensorflow:loss = 40.3296, step = 1101 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.486\n",
      "INFO:tensorflow:loss = 1229.09, step = 1201 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.336\n",
      "INFO:tensorflow:loss = 46.6686, step = 1301 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.48\n",
      "INFO:tensorflow:loss = 168.933, step = 1401 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.48\n",
      "INFO:tensorflow:loss = 131.448, step = 1501 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.254\n",
      "INFO:tensorflow:loss = 64.2324, step = 1601 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 152.117, step = 1701 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.481\n",
      "INFO:tensorflow:loss = 130.78, step = 1801 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.028\n",
      "INFO:tensorflow:loss = 48.3393, step = 1901 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.047\n",
      "INFO:tensorflow:loss = 641.627, step = 2001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.569\n",
      "INFO:tensorflow:loss = 42.6198, step = 2101 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.662\n",
      "INFO:tensorflow:loss = 119.509, step = 2201 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.866\n",
      "INFO:tensorflow:loss = 42.6134, step = 2301 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.598\n",
      "INFO:tensorflow:loss = 110.165, step = 2401 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.029\n",
      "INFO:tensorflow:loss = 145.465, step = 2501 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.848\n",
      "INFO:tensorflow:loss = 98.5642, step = 2601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.742\n",
      "INFO:tensorflow:loss = 28.075, step = 2701 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.043\n",
      "INFO:tensorflow:loss = 88.1087, step = 2801 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.855\n",
      "INFO:tensorflow:loss = 181.19, step = 2901 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.488\n",
      "INFO:tensorflow:loss = 72.0171, step = 3001 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 56.6596, step = 3101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.254\n",
      "INFO:tensorflow:loss = 66.3351, step = 3201 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.461\n",
      "INFO:tensorflow:loss = 123.457, step = 3301 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.337\n",
      "INFO:tensorflow:loss = 82.7712, step = 3401 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.117\n",
      "INFO:tensorflow:loss = 98.0098, step = 3501 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.447\n",
      "INFO:tensorflow:loss = 138.926, step = 3601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.76\n",
      "INFO:tensorflow:loss = 87.8101, step = 3701 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.661\n",
      "INFO:tensorflow:loss = 81.6794, step = 3801 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.598\n",
      "INFO:tensorflow:loss = 29.9681, step = 3901 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.898\n",
      "INFO:tensorflow:loss = 48.5151, step = 4001 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.323\n",
      "INFO:tensorflow:loss = 397.157, step = 4101 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.046\n",
      "INFO:tensorflow:loss = 77.1086, step = 4201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.662\n",
      "INFO:tensorflow:loss = 39.8334, step = 4301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.17\n",
      "INFO:tensorflow:loss = 46.994, step = 4401 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.117\n",
      "INFO:tensorflow:loss = 63.4313, step = 4501 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.047\n",
      "INFO:tensorflow:loss = 140.491, step = 4601 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.903\n",
      "INFO:tensorflow:loss = 46.4321, step = 4701 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.336\n",
      "INFO:tensorflow:loss = 41.9023, step = 4801 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.663\n",
      "INFO:tensorflow:loss = 36.1105, step = 4901 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.65\n",
      "INFO:tensorflow:loss = 42.4661, step = 5001 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.184\n",
      "INFO:tensorflow:loss = 116.188, step = 5101 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.48\n",
      "INFO:tensorflow:loss = 40.0166, step = 5201 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.333\n",
      "INFO:tensorflow:loss = 48.9138, step = 5301 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.898\n",
      "INFO:tensorflow:loss = 35.2169, step = 5401 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.539\n",
      "INFO:tensorflow:loss = 42.1799, step = 5501 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.96\n",
      "INFO:tensorflow:loss = 35.2441, step = 5601 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.479\n",
      "INFO:tensorflow:loss = 124.86, step = 5701 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.743\n",
      "INFO:tensorflow:loss = 79.1828, step = 5801 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.076\n",
      "INFO:tensorflow:loss = 31.8402, step = 5901 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.217\n",
      "INFO:tensorflow:loss = 41.2924, step = 6001 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.331\n",
      "INFO:tensorflow:loss = 48.8319, step = 6101 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.029\n",
      "INFO:tensorflow:loss = 88.1098, step = 6201 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.71\n",
      "INFO:tensorflow:loss = 32.5181, step = 6301 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.251\n",
      "INFO:tensorflow:loss = 25.0635, step = 6401 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.078\n",
      "INFO:tensorflow:loss = 36.4295, step = 6501 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.253\n",
      "INFO:tensorflow:loss = 54.1682, step = 6601 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.48\n",
      "INFO:tensorflow:loss = 82.7159, step = 6701 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.745\n",
      "INFO:tensorflow:loss = 31.4761, step = 6801 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.046\n",
      "INFO:tensorflow:loss = 29.9435, step = 6901 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.446\n",
      "INFO:tensorflow:loss = 46.1997, step = 7001 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.645\n",
      "INFO:tensorflow:loss = 83.2707, step = 7101 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.655\n",
      "INFO:tensorflow:loss = 36.9569, step = 7201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.253\n",
      "INFO:tensorflow:loss = 46.9615, step = 7301 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.848\n",
      "INFO:tensorflow:loss = 41.7492, step = 7401 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.44\n",
      "INFO:tensorflow:loss = 44.4146, step = 7501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.861\n",
      "INFO:tensorflow:loss = 44.223, step = 7601 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.256\n",
      "INFO:tensorflow:loss = 33.7452, step = 7701 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.324\n",
      "INFO:tensorflow:loss = 42.9637, step = 7801 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.17\n",
      "INFO:tensorflow:loss = 33.5727, step = 7901 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.047\n",
      "INFO:tensorflow:loss = 35.5778, step = 8001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.486\n",
      "INFO:tensorflow:loss = 31.3465, step = 8101 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.334\n",
      "INFO:tensorflow:loss = 100.144, step = 8201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.867\n",
      "INFO:tensorflow:loss = 22.7521, step = 8301 (0.405 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 243.254\n",
      "INFO:tensorflow:loss = 27.355, step = 8401 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.849\n",
      "INFO:tensorflow:loss = 109.076, step = 8501 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.091\n",
      "INFO:tensorflow:loss = 124.492, step = 8601 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.338\n",
      "INFO:tensorflow:loss = 70.8065, step = 8701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.093\n",
      "INFO:tensorflow:loss = 24.326, step = 8801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.589\n",
      "INFO:tensorflow:loss = 40.8559, step = 8901 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.745\n",
      "INFO:tensorflow:loss = 53.5762, step = 9001 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.455\n",
      "INFO:tensorflow:loss = 76.0751, step = 9101 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.102\n",
      "INFO:tensorflow:loss = 42.3494, step = 9201 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.713\n",
      "INFO:tensorflow:loss = 44.8572, step = 9301 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.588\n",
      "INFO:tensorflow:loss = 52.3668, step = 9401 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.132\n",
      "INFO:tensorflow:loss = 82.138, step = 9501 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.219\n",
      "INFO:tensorflow:loss = 30.0302, step = 9601 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.335\n",
      "INFO:tensorflow:loss = 34.2165, step = 9701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.651\n",
      "INFO:tensorflow:loss = 53.2306, step = 9801 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.713\n",
      "INFO:tensorflow:loss = 80.207, step = 9901 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.848\n",
      "INFO:tensorflow:loss = 40.8277, step = 10001 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.046\n",
      "INFO:tensorflow:loss = 41.0924, step = 10101 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 79.8695, step = 10201 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.219\n",
      "INFO:tensorflow:loss = 58.7572, step = 10301 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.651\n",
      "INFO:tensorflow:loss = 169.911, step = 10401 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 61.9662, step = 10501 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.093\n",
      "INFO:tensorflow:loss = 29.1523, step = 10601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.962\n",
      "INFO:tensorflow:loss = 61.561, step = 10701 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.712\n",
      "INFO:tensorflow:loss = 25.5236, step = 10801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.854\n",
      "INFO:tensorflow:loss = 80.761, step = 10901 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 36.3799, step = 11001 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 46.2259, step = 11101 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.65\n",
      "INFO:tensorflow:loss = 50.1335, step = 11201 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.215\n",
      "INFO:tensorflow:loss = 20.6714, step = 11301 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.101\n",
      "INFO:tensorflow:loss = 43.79, step = 11401 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.867\n",
      "INFO:tensorflow:loss = 92.8642, step = 11501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.662\n",
      "INFO:tensorflow:loss = 29.6356, step = 11601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.025\n",
      "INFO:tensorflow:loss = 27.1353, step = 11701 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.87\n",
      "INFO:tensorflow:loss = 115.694, step = 11801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.095\n",
      "INFO:tensorflow:loss = 20.9861, step = 11901 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.335\n",
      "INFO:tensorflow:loss = 27.4734, step = 12001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.657\n",
      "INFO:tensorflow:loss = 35.1999, step = 12101 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.718\n",
      "INFO:tensorflow:loss = 38.9622, step = 12201 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 37.8959, step = 12301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.866\n",
      "INFO:tensorflow:loss = 52.9687, step = 12401 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.588\n",
      "INFO:tensorflow:loss = 33.369, step = 12501 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.65\n",
      "INFO:tensorflow:loss = 29.5076, step = 12601 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.461\n",
      "INFO:tensorflow:loss = 33.0083, step = 12701 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.589\n",
      "INFO:tensorflow:loss = 20.9667, step = 12801 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.046\n",
      "INFO:tensorflow:loss = 90.4802, step = 12901 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.439\n",
      "INFO:tensorflow:loss = 31.8198, step = 13001 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.053\n",
      "INFO:tensorflow:loss = 31.5125, step = 13101 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.254\n",
      "INFO:tensorflow:loss = 67.766, step = 13201 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.713\n",
      "INFO:tensorflow:loss = 28.6147, step = 13301 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.476\n",
      "INFO:tensorflow:loss = 43.8413, step = 13401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.87\n",
      "INFO:tensorflow:loss = 36.57, step = 13501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.073\n",
      "INFO:tensorflow:loss = 31.4901, step = 13601 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 49.0894, step = 13701 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.713\n",
      "INFO:tensorflow:loss = 90.3252, step = 13801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.253\n",
      "INFO:tensorflow:loss = 240.858, step = 13901 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.095\n",
      "INFO:tensorflow:loss = 59.2107, step = 14001 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.588\n",
      "INFO:tensorflow:loss = 55.0139, step = 14101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.337\n",
      "INFO:tensorflow:loss = 27.0411, step = 14201 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.745\n",
      "INFO:tensorflow:loss = 27.9857, step = 14301 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 50.8649, step = 14401 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.491\n",
      "INFO:tensorflow:loss = 46.5823, step = 14501 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.023\n",
      "INFO:tensorflow:loss = 64.5939, step = 14601 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.051\n",
      "INFO:tensorflow:loss = 34.5874, step = 14701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.323\n",
      "INFO:tensorflow:loss = 36.9614, step = 14801 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.868\n",
      "INFO:tensorflow:loss = 35.674, step = 14901 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 22.6361, step = 15001 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.094\n",
      "INFO:tensorflow:loss = 43.8368, step = 15101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.487\n",
      "INFO:tensorflow:loss = 72.7504, step = 15201 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 37.4784, step = 15301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.046\n",
      "INFO:tensorflow:loss = 27.542, step = 15401 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.067\n",
      "INFO:tensorflow:loss = 47.8388, step = 15501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.751\n",
      "INFO:tensorflow:loss = 38.4567, step = 15601 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.849\n",
      "INFO:tensorflow:loss = 32.8318, step = 15701 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.023\n",
      "INFO:tensorflow:loss = 37.9552, step = 15801 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.952\n",
      "INFO:tensorflow:loss = 43.6645, step = 15901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.658\n",
      "INFO:tensorflow:loss = 23.6667, step = 16001 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.094\n",
      "INFO:tensorflow:loss = 39.8757, step = 16101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.487\n",
      "INFO:tensorflow:loss = 30.7626, step = 16201 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.095\n",
      "INFO:tensorflow:loss = 23.8515, step = 16301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.595\n",
      "INFO:tensorflow:loss = 67.317, step = 16401 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.717\n",
      "INFO:tensorflow:loss = 44.7516, step = 16501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.486\n",
      "INFO:tensorflow:loss = 136.788, step = 16601 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.253\n",
      "INFO:tensorflow:loss = 52.9357, step = 16701 (0.410 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 242.662\n",
      "INFO:tensorflow:loss = 44.5281, step = 16801 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 34.9702, step = 16901 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 25.3596, step = 17001 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.589\n",
      "INFO:tensorflow:loss = 74.3587, step = 17101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.713\n",
      "INFO:tensorflow:loss = 33.7972, step = 17201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.854\n",
      "INFO:tensorflow:loss = 35.3692, step = 17301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.853\n",
      "INFO:tensorflow:loss = 47.4463, step = 17401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.651\n",
      "INFO:tensorflow:loss = 52.47, step = 17501 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.334\n",
      "INFO:tensorflow:loss = 37.8384, step = 17601 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.961\n",
      "INFO:tensorflow:loss = 41.4469, step = 17701 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.866\n",
      "INFO:tensorflow:loss = 32.3561, step = 17801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.333\n",
      "INFO:tensorflow:loss = 43.8372, step = 17901 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.481\n",
      "INFO:tensorflow:loss = 25.6236, step = 18001 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.094\n",
      "INFO:tensorflow:loss = 28.5022, step = 18101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.849\n",
      "INFO:tensorflow:loss = 36.7407, step = 18201 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.323\n",
      "INFO:tensorflow:loss = 33.9359, step = 18301 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.867\n",
      "INFO:tensorflow:loss = 46.131, step = 18401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.853\n",
      "INFO:tensorflow:loss = 26.7136, step = 18501 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.65\n",
      "INFO:tensorflow:loss = 30.2667, step = 18601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.095\n",
      "INFO:tensorflow:loss = 34.2151, step = 18701 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.479\n",
      "INFO:tensorflow:loss = 33.9146, step = 18801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.257\n",
      "INFO:tensorflow:loss = 30.7834, step = 18901 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.903\n",
      "INFO:tensorflow:loss = 33.3782, step = 19001 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.074\n",
      "INFO:tensorflow:loss = 51.3104, step = 19101 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.96\n",
      "INFO:tensorflow:loss = 34.7065, step = 19201 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.959\n",
      "INFO:tensorflow:loss = 29.1265, step = 19301 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.074\n",
      "INFO:tensorflow:loss = 25.5738, step = 19401 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.324\n",
      "INFO:tensorflow:loss = 37.7558, step = 19501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.445\n",
      "INFO:tensorflow:loss = 95.0368, step = 19601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.446\n",
      "INFO:tensorflow:loss = 20.5691, step = 19701 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.96\n",
      "INFO:tensorflow:loss = 32.6886, step = 19801 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.073\n",
      "INFO:tensorflow:loss = 30.8219, step = 19901 (0.412 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into C:\\Users\\FRKSTE~1\\AppData\\Local\\Temp\\tmppfx84drb\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 51.2147.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x244e88e7358>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model.train(input_fn=input_func, steps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\FRKSTE~1\\AppData\\Local\\Temp\\tmppfx84drb\\model.ckpt-20000\n"
     ]
    }
   ],
   "source": [
    "predictions = list(lin_model.predict(pred_input_func))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0]['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []\n",
    "for pred in predictions:\n",
    "    id_list.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.93      0.88      7436\n",
      "          1       0.66      0.43      0.52      2333\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
